\documentclass{book}
\usepackage{lmodern}
\usepackage{polyglossia}
\setmainlanguage{english}
\usepackage{./main}
\title{Electronic Document Preparation: An Author's Cookbook}
\author{Petr Sojka, Vít Novotný}
\date{\today}
\begin{document}
  \frontmatter
    \maketitle
    \tableofcontents
  \mainmatter
    \chapter{Foreword}
      With the advent of the digital age, typesetting has become available to
      virtually anyone equipped with a personal computer. Beautiful documents
      can now be crafted using free and consumer-grade software, which often
      obviates the need for the involvement of a professional designer and
      typesetter. The level playing field of the Internet coupled with the
      rising popularity of digital-only documents then allows the aspiring
      author to bypass the publisher as well, if they so wish, without
      jeopardizing their chance of recognition.
      
      This text is intended as a handbook for any author who aspires to write,
      design, typeset and distribute high-quality documents of their own making.
      Each chapters describes one discrete step in the process of the creation
      of a document and their order corresponds to the realities of document
      preparation, allowing the author to break the process down to manageable
      parts and tackle each of them separately. This also allows for the
      separation of labour, where each part of the process can be completed
      independently by a different specialist. However, a lone author who is
      preparing a less complex document or who feels confident in their ability
      to multitask may find it more productive to interleave several steps of
      the document preparation process.

    \chapter{Writing}
      % Text encodings
      % Text editors
      % Regular expressions
      % Versioning systems

    \chapter{Markup}
      A manuscript can consist of a seamless river of words and still make
      perfect sense to the author. To truly capture its meaning in a clear and
      unambiguous manner, however, the manuscript will often need to be
      supplemented with a set of annotations. At a more basic level, this refers
      to the compliance with the orthographic rules, such as the correct
      spelling, hyphenation, capitalization, word breaks and punctuation, that
      are specific to the language of the document. It is not at all
      unreasonable to expect that this basic compliance should be already met by
      the manuscript.  At a higher level, this consists of discovering and
      marking up the inner order and the logic of the text, so that the
      resulting document can later be typeset in a way that visually reflects
      the structure of the text.
      
      To this end, there exists a wealth of \emph{markup languages} that enable
      the enrichment of text with additional information and labels. Aside from
      \emph{logical markup}, which enables the capture of the logical structure
      of the document, markup languages may also provide \emph{presentation
      markup}, which directly impacts the visual properties of the document, but
      carries no semantic information. The usage of presentation markup instead
      of logical markup makes it impossible to separate the markup from the
      design of the document and to capture the logic of the text. As a result,
      the unity of the design of each logical part of the document would have to
      be ensured manually and future changes of design would become tedious. It
      is for these reasons that the usage of presentation markup is discouraged
      in favour of logical markup.

      \section{Meta Markup Languages}
      \subsection{The General Markup Language}
        As described in \cite{hlava11}, the situation engulfing digital
        typesetting was growing increasingly frustrating for publishers in the
        1960s. The markup languages used by different typesetting systems varied
        wildly and once a publisher had a large collection of documents typeset
        via a given company, switching to another one could be very costly. The
        companies would often take advantage of this situation, causing their
        prices to skyrocket. As a result of that, a demand for a universal
        markup language emerged.

        This demand was met by a side product of a project developed\footnote{
          More information about the project can be found within the personal
          recollections of its co-author, Charles F. Goldfarb, in
          \cite{goldfarb96} and \cite{goldfarb97:whySGML}.
        } at the \acronym{IBM}'s Cambridge Scientific Center in the early 1970s.
        The project aimed at imbuing a text editor with the ability to query,
        edit and display documents from a repository to allow the usage of
        computers in legal practice. Very early on in the development process,
        it became clear that the crux was going to be the markup languages in
        which the documents were written. These languages were not unified and
        many of them comprised largely presentation markup, which made
        information retrieval impossible without the use of heuristics. To
        resolve the issue, a unifying markup language called the General Markup
        Language (\acronym{GML}) was drafted as a solution to the decribed
        problem. The language was later released to the public in
        \cite{goldfarb81} and finally standardized\footnote{
          The authoritative resource on the \acronym{SGML} language is
          \cite{goldfarb91}, which includes the full text of the standard along
          with the author's extensive annotations.
        } as the Standard General Markup Language (\acronym{SGML}) within
        \cite{iso8879}.

        \acronym{SGML} documents consist of text mixed with \emph{tags}, which
        delimit meaningful sections of the document called \emph{elements}.
        Elements can carry additional information in \emph{attributes}. A
        \acronym{SGML} document can also contain miscellaneous processing
        instructions for the application as well as human-readable comments.
        Repeated strings of text can be declared as \emph{entities} that can
        consequently be used throughout the document in place of the original
        strings.
        
        Although the described structure is shared by all \acronym{SGML}
        documents, the actual syntax, as well as the restrictions with regards
        to the contents and the attributes of individual elements, are declared
        within a Document Type Declaration (\acronym{DTD}), which can be
        different for each document. It is worth noting that a \acronym{DTD}
        only declares the syntax of an \acronym{SGML} document and the semantics
        of the individual elements and their attributes are left to the
        interpretation of the program processing the document. The syntax and
        the constraints imposed by a \acronym{DTD} define an \emph{application}
        of \acronym{SGML}. An \acronym{SGML} document is considered to be a
        valid instance of an \acronym{SGML} application, when it conforms to the
        respective \acronym{DTD}.

      \subsection{The Extensible Markup Language}
        Although \acronym{SGML} was designed to be the general format for data
        exchange, the complexity of the specification and the lack of support
        for Unicode proved to be a major hindrance preventing its wider
        adoption and tool development. As a response, the World Wide Web
        Consortium (W3C) published a specification of the Extensible Markup
        Language (\acronym{XML}) within \cite{bray98} in 1998. Along with the
        introduction of \acronym{XML}, the \acronym{SGML} specification received
        a technical corrigendum of \cite{goldfarb97:webSGML}, which turned
        \acronym{XML} into a proper subset of \acronym{SGML} restrained by an
        \acronym{SGML} \acronym{DTD}.
        
        This \acronym{DTD} completely fixes the syntax of \acronym{XML}
        documents, which makes it possible to differentiate two levels of
        correctness. Specifically, an \acronym{XML} document is considered to be
        \emph{well-formed}, when it conforms to the \acronym{SGML} \acronym{DTD}
        that restrains \acronym{XML} as well as to the additional constraints
        given in the specification. An \acronym{XML} document is considered to
        be \emph{valid} against an \acronym{XML} \acronym{DTD}, when it
        is well-formed and conforms to the said \acronym{XML} \acronym{DTD}.
        Along with \acronym{DTD}s, there exists a wealth of \emph{schema}
        languages for \acronym{XML}, such as \acronym{W3C XML} Schema, Regular
        Language for \acronym{XML} Next Generation (\acronym{Relax NG}) or
        Schematron that can be used to check the validity of an \acronym{XML}
        document instead of a \acronym{DTD}. The constrains imposed by either a
        \acronym{DTD} or a schema define an \emph{application}, \emph{language}
        or \emph{format} of \acronym{XML}.

          % Examples of various XML schema languages and DTD (https://en.wikipedia.org/wiki/Document_type_definition)
          % Examples of validity testing
        
        Along with schema languages, other supplementary languages also exist,
        such as XPointer, XPath and XQuery for addressing sets of elements
        (fragments) within a \acronym{XML} document or Cascading Style Sheet
        language (\acronym{CSS}) for specifying the visual properties of an
        \acronym{XML} document. While some of these languages may not be
        \acronym{XML} languages, they are nevertheless used within documents of
        various \acronym{XML} formats and form an important part of the
        \acronym{XML} ecosystem.

        %%% XML Namespaces and the discussion of their usefulness compared to
        %%% Architectural Forms (AFs)
        %%%  <http://users.nyct.net/~aray/sgo/bogosity.txt>
        %%%  <http://www.w3.org/TR/1999/REC-xml-names-19990114/>
        %%%  <https://msdn.microsoft.com/en-us/library/aa468565.aspx>

        Due to the reduced complexity of \acronym{XML} compared to
        \acronym{SGML}, the language was adopted by specialists and the general
        public alike and has superseded \acronym{SGML} in many applications.
        Some of the applications of \acronym{XML} for document
        preparation include DocBook\footnote{
          The authoritative resource on the DocBook \acronym{XML} format is
          \cite{walsh10}. The book itself is written in DocBook and its source
          code is publicly available at the Web page at
          \url{http://docbook.org}.
        }---a technical documentation format used for authoring books by
        publishers such as O'Reilly Media and for documenting software at
        companies such as Red Hat, \acronym{SUSE} or Sun Microsystems---,
        Text Encoding Initiative (\acronym{TEI})---a general text encoding
        format for the use in the academic field of digital humanities---,
        Mathematical Markup Language (\acronym{MathML})---a format for
        describing mathematical formulae---, or Scalable Vector Graphics
        (\acronym{SVG})---a two-dimensional vector image format. Other
        \acronym{XML} applications, such as \acronym{XHTML} and
        \acronym{RDF/XML}, will be described in Section \ref{sec:www-markup}.
        
      \section{Markup on the World Wide Web}\label{sec:www-markup}
      \subsection{The Hypertext Markup Language}
        In 1989, Timothy John Berners-Lee proposed in \cite{bernerslee89} a
        decentralized system for sharing linked documents within \acronym{CERN}.
        The system laid foundation for today's World Wide Web (Web) and earned
        its author knighthood. The markup language used to write documents for
        the system was an application of \acronym{SGML} called the HyperText
        Markup Language (\acronym{HTML}). In 1993, the Web started to gain
        popularity amongst the general public due to the release of the first
        graphical Web browser Mosaic, which paved way for the Web browsers of
        today. In 1994, Timothy John Berners-Lee formed the World Wide Web
        Consortium (\acronym{W3C}), which has since been developing the
        standards for the Web.
        
        %%% On the various meanings of <tag /> <https://utcc.utoronto.ca/~cks/space/blog/web/ShortTagsMeanings>

        The first standard version of \acronym{HTML} was version 2.0 published
        as \cite{rfc1866} in 1995. As the Web was becoming ubiquitous, it began
        accumulating an increasing number of documents that weren't valid
        instances of \acronym{HTML}, since most Web browsers, when faced with a
        malformed document, would act in accordance with the Postel's law and
        try to render the document despite its deficiencies. In an attempt to
        unify the way malformed \acronym{HTML} documents were rendered across
        the Web browsers, \acronym{W3C} acknowledged and documented this
        behaviour as a part of \cite[Section~8.2, Parsing HTML
        documents]{hickson14} in 2008.

          % Example of a valid HTML5 document that is an invalid SGML
          % application instance (overlapping tags, tag soup)

        Initially, \acronym{HTML} comprised a mixture of logical and
        presentation markup with fixed visual interpretation. In 1996, a
        specification of a Cascading Style Sheet (\acronym{CSS}) language was
        published by \acronym{W3C} within \cite{lie96}. The language enabled
        the specification of the visual properties of any element, which allowed
        for the separation of document markup and design, effectively
        eliminating the need for the presentation markup.

          % Example of the usage of CSS in favour of presentation markup

        During the same period, an initial version of a scripting language
        called JavaScript was drafted and incorporated into Netscape Navigator
        2.0, one of the contemporary leading web browsers and a descendant of
        the original Mosaic browser. As a part of a joint effort to bring Java
        into web browsers by Sun Microsystems and Netscape Communications,
        JavaScript was, according to \cite{js-announcement}, supposed to
        complement Java applets -- a role it has since outgrown. Standardized
        within \cite{ecma1} in 1997, JavaScript blurs the line between static
        documents and interactive applications and remains the predominant
        client-side programming language for the Web.  However, since the
        support of JavaScript by a Web browser is fully optional, it is
        considered a good practice to use it chiefly for the enrichment of
        already self-sufficient \acronym{HTML} documents. In case of an
        interactive application, this recommendation can be relaxed.

          % Example of the usage of JavaScript
          % Relevant literature

      \subsection{The Extensible Hypertext Markup Language}
        Ever since the release of \acronym{XML} in 1998, \acronym{W3C}
        entertained the idea of turning \acronym{HTML} into an application of
        \acronym{XML}, rather than \acronym{SGML}, as exemplified by the working
        draft of \cite{raggett98} released the very same year. Unlike
        \acronym{HTML} parsers, which are complex in their acceptance of
        malformed content, \acronym{XML} parsers are, as per \cite[Section~1.2,
        Terminology]{bray98}, required to draconianly refuse \acronym{XML}
        documents that aren't well-formed, leading to architectural simplicity
        and decreased computational requirements. As a result, reformulating
        \acronym{HTML} in \acronym{XML} was suggested as a way to bring the Web
        to mobile, embedded and other devices limited in their resources, as
        well as to reduce the amount of malformed documents on the Web in
        general. Other perceived advantages included the ability to use
        \acronym{XML} tools for web documents and to include instances of other
        \acronym{XML} applications, such as \acronym{MathML} and \acronym{SVG},
        directly into web documents using \acronym{XML} name spaces.

        The idea was brought to fruition within \cite{pemberton00} in 2000 as an
        \acronym{XML} application called the Extensible HyperText Markup
        Language (\acronym{XHTML}), which was met with lukewarm reception, since
        many of its supposed benefits proved to be either questionable or too
        marginal to warrant migration from \acronym{HTML}.  The speed
        improvements of the simpler parser were largely offset by its lack of
        support for incremental rendering, caused by the impossibility to
        validate partially downloaded pages, the closing of the gap in the
        computing power between mobile and desktop devices made it possible to
        use full-fledged \acronym{HTML} parsers instead, and the lack of ways to
        provide alternative content for browsers that would not support directly
        included the \acronym{XML} documents considerably reduced the usefulness
        of name spaces. As a result, \acronym{XHTML} did not succeed in
        replacing \acronym{HTML} and remains an alternative markup language for
        the Web.

          % An example of an XHTML document

        %%% Content-Negotiation Techniques to serve XHTML as text/html and
        %%% application/xhtml+xml
        %%%   <http://www.w3.org/2003/01/xhtml-mimetype/content-negotiation>

      \subsection{The Semantic Web and Microdata}
        The underlying fundament of the Web is the the idea of a globally
        available and incrementally scalable base of human knowledge.
        \acronym{HTML} and \acronym{XHTML} succeeded in fulfilling this vision
        for human-readable documents, but didn't provide a unifying
        machine-readable format for the representation of structured information
        that would enable the creation of a web of linked data running in
        parallel to the web of documents. In 1999, \acronym{W3C} released
        \cite{lassira99} containing the specification of the Resource
        Description Framework (\acronym{RDF}), a method for the description of
        resources on the Web.

        Drawing from the research in the field of knowledge representation, an
        \acronym{RDF} document represents data as a set of \emph{triples}. Each
        of the triplets comprises \emph{a predicate}, \emph{a subject} and
        \emph{an object}, where both the subject and the predicate are specified
        as \emph{resources} using Internationalized Resource Identifiers
        (\acronym{IRI}s) as defined within \cite{rfc3987}. If the object of a
        triplet $(p,s,o)$ is also a resource, the triplet can be interpreted as
        a subject $s$ being in a relation $p$ with an object $o$. If the object
        is a \emph{literal value} rather than a resource, the respective triplet
        can be interpreted as a subject $s$ having a property $p$ with a value
        $o$.

        Resources in \acronym{RDF} are specified via \acronym{IRI}s to prevent
        naming collisions in \acronym{RDF} documents created independently by
        distinct authors. These \acronym{IRI}s are not required to resolve to an
        actual web page and, disregarding the small set of standard resources
        specified within the \acronym{RDF} specification, they carry no inherent
        meaning.  In order to describe a set of resources, the relationships
        between them and their intended meaning in an \acronym{RDF} document, an
        extended set of standard resources called \acronym{RDF} Schema and
        specified within \cite{brickley04} can be used. The resulting documents
        are called \emph{ontologies} and can be used for automated reasoning
        about \acronym{RDF} documents containing resources described by the
        ontology.\footnote{
          A list of ontologies that are fully documented, honor the current best
          practices and are supported by various tools can be found on the
          \acronym{W3C} wiki at \url{http://www.w3.org/wiki/Good_Ontologies}.
        } Some of the well-known ontologies include Dublin
        Core (\acronym{DC})---an ontology for the generic description of both
        web multimedia and physical objects---, Friend or a Foe
        (\acronym{FOAF})---an ontology for the description of people and their
        social relationships---, or the Music Ontology---an ontology for the
        description of entities related to the music industry, such as albums,
        artists, tracks and events. More expressive standards for the creation
        of ontologies, such as the Web Ontology Language (\acronym{OWL})
        specified within \cite{mcguinness04}, also exist.

        The syntax of \acronym{RDF} is not fixed, meaning that aside from the
        \acronym{XML} serialization specified within \cite{lassira99}, other
        languages, such as the JavaScript Object Notation for Linked Data
        (\acronym{JSON-LD}) specified within \cite{sporny14} or the line-based
        N-Triples specified within \cite{beckett14}, can be used to represent an
        \acronym{RDF} document. A noteworthy serialization of \acronym{RDF} is
        the \acronym{RDF} in attributes (\acronym{RDFa}) specified within
        \cite{adida08}. While various serializations of \acronym{RDF} can be
        included in or linked to an \acronym{HTML} or \acronym{XHTML} document,
        this will often result in an undesirable duplication of data already
        present in the document. To prevent this, \acronym{RDFa} uses the
        content already present within the underlying \acronym{HTML} or
        \acronym{XHTML} document using element attributes. The usage of
        \acronym{RDF} in conjunction with \acronym{HTML} and \acronym{XHTML} is
        intended to gradually obsolete the practice of using the \texttt{meta}
        and \texttt{link} elements to provide additional application-specific
        metadata about the document.

          % Examples of Dublin Core
          % Examples of RDF usage and serialization (see wiki) + nodes and arcs graph 
          % Examples of SPARQL queries

        %%% Tim Berners-Lee: The next web
        %%%   <http://www.ted.com/talks/tim_berners_lee_on_the_next_web>
        %%%
        %%% The SPARQL Query Language for RDF (SPARQL) and the (at the time of
        %%% writing only drafted) Linked Data Fragments RDF query interfaces
        %%%   <http://www.w3.org/TR/rdf-sparql-query/>
        %%%   <http://linkeddatafragments.org/specification/>
        %%%
        %%% The Rule Interchange Format (RIF)
        %%%   <http://www.w3.org/TR/rif-overview/>
        
      \section{Markup in Document Processing Systems}
        % Batch-oriented
          % troff / groff / nroff / runoff, UNIX manpages
          % LaTeX
          % lout
        % WYSIWYG
          % Word, OpenOffice, Adobe InDesign, Scribus
          %%% Style basics in Word <https://support.office.com/en-nz/article/Style-basics-in-Word-d382f84d-5c38-4444-98a5-9cbb6ede1ba4>
          %%% InDesign Help / Paragraph and character style <https://helpx.adobe.com/indesign/using/paragraph-character-styles.html>
          %%% Format text with Paragraph Styles <https://helpx.adobe.com/indesign/how-to/indesign-formatting-text-paragraph-styles.html>

      \section{Lightweight Markup Languages}
        %%% Lightweight markup language <https://en.wikipedia.org/wiki/Lightweight_markup_language>

    \chapter{Design}
      % XML -- CSS, XSL, XSLT
    \chapter{Typesetting}
    \chapter{Proofreading}
    \chapter{Printing}
    \chapter{Distribution}
\end{document}
